{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NLP of SEG Geophysics journal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this first notebook I use some basic web scraping packages to extract information from the digital library of Geophysics journal of Society of Exploration Geophysicists. \n",
    "\n",
    "In the following notebook such information will be used to obtain more or less useful (and interesting) statistics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First of all let's import some useful packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import glob \n",
    "from datetime import datetime,date\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import display\n",
    "\n",
    "from utils import *\n",
    "\n",
    "\n",
    "# Figures inline and set visualization style\n",
    "%matplotlib inline\n",
    "sns.set()\n",
    "sns.set_style(\"whitegrid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Web scraping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start choosing where data downloaded from SEG website will be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pathSEG='./data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get web-links of all the Available Volumes and Issues in Geophysics journal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url='http://library.seg.org/loi/gpysa7' # List of volumes\n",
    "\n",
    "# Make the request \n",
    "r = requests.get(url)\n",
    "\n",
    "# Extract HTML from Response object and print\n",
    "html = r.text\n",
    "#print html\n",
    "\n",
    "# Create a BeautifulSoup object from the HTML\n",
    "soup = BeautifulSoup(html, \"html5lib\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First interesting fact, the next block will show the number of volumes in Geophysics journal present today"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Geophysics Volumes: 543 \n"
     ]
    }
   ],
   "source": [
    "# Create tokenizer to find weblinks for all volumes of Geophysics\n",
    "tokenizer = RegexpTokenizer('\"((http)s?://library.seg.org/toc/gpysa7/[0-9].*?)\"')\n",
    "volumes = tokenizer.tokenize(html)\n",
    "\n",
    "# Remove first volume as it contains articles that have just been accepted.\n",
    "volumes = volumes[1:] \n",
    "\n",
    "print('Number of Geophysics Volumes: %d ' % len(volumes))\n",
    "#print volumes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by finding categories in a single issue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Editor's corner: 1\n",
      "Geophysics Letters: 2\n",
      "Case Histories: 3\n",
      "Anisotropy: 4\n",
      "Borehole Geophysics: 8\n",
      "Electrical and Electromagnetic Methods: 6\n",
      "Gravity Exploration Methods: 2\n",
      "Magnetic Resonance Sounding: 1\n",
      "Passive Seismic Methods: 1\n",
      "Reservoir Geophysics: 2\n",
      "Seismic Interferometry : 1\n",
      "Seismic Inversion: 6\n",
      "Seismic Migration: 9\n",
      "Seismic Modeling and Wave Propagation: 3\n",
      "Seismic Velocity/Statics: 3\n",
      "Signal Processing: 5\n",
      "Errata: 3\n"
     ]
    }
   ],
   "source": [
    "volume = 'https://library.seg.org/toc/gpysa7/82/2'\n",
    "\n",
    "r    = requests.get(volume)\n",
    "html = r.text\n",
    "cat  = find_categories(r.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I take now one article and learn how to get useful information:\n",
    "\n",
    "- Title\n",
    "- Authors\n",
    "- Keywords\n",
    "- Abstract\n",
    "- Publication history\n",
    "- Affiliations/Countries\n",
    "- Number of citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Authors:', [u'Joost van der Neut', u'Matteo Ravasi', u'Yi Liu', u'Ivan Vasconcelos'])\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-bb87f746d611>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[0mkeywords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\"'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'utf8'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0;31m#print keywords\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m \u001b[0mkeywords\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mlambda\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m';'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Keywords:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mkeywords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "r = requests.get('https://library.seg.org/doi/abs/10.1190/geo2017-0166.1')\n",
    "\n",
    "html = r.text\n",
    "soup = BeautifulSoup(html, \"html5lib\")\n",
    "info = soup.findAll('meta')\n",
    "#print info\n",
    "\n",
    "# authors\n",
    "author = filter(lambda x: 'dc.Creator' in str(x), info)\n",
    "#print author\n",
    "author  = map(lambda x: str(x).split('\"')[1].decode('utf8'), author)\n",
    "print('Authors:',author)\n",
    "\n",
    "# keywords\n",
    "keywords = filter(lambda x: 'dc.Subject' in str(x), info)\n",
    "#print keywords\n",
    "keywords = map(lambda x: str(x).split('\"')[1].decode('utf8'), keywords)\n",
    "#print keywords\n",
    "keywords = map(lambda x: str(x).split(';'), keywords)[0]\n",
    "print('Keywords:',keywords)\n",
    "\n",
    "\n",
    "# abstract\n",
    "abstract = filter(lambda x: 'dc.Description' in str(x), info)\n",
    "#print abstract\n",
    "abstract = map(lambda x: str(x).split('\"')[1].decode('utf8'), abstract)[0][8:]\n",
    "print abstract\n",
    "print('Abstract:',abstract)\n",
    "\n",
    "\n",
    "# publication history\n",
    "info = soup.findAll(text=re.compile(\"Received:|Accepted:|Published:\"))\n",
    "print info\n",
    "received, accepted, published = get_pubhistory(info)\n",
    "print received, accepted, published\n",
    "\n",
    "# countries\n",
    "info = soup.findAll('span')\n",
    "country = filter(lambda x: 'country' in str(x), info)\n",
    "country = map(lambda x: str(x).split('>')[1].split('<')[0].decode('utf8'), country)\n",
    "print country\n",
    "print('Country:',country)\n",
    "\n",
    "\n",
    "# affiliations\n",
    "info = soup.findAll('span')\n",
    "affiliation = filter(lambda x: 'class=\"institution\"' in str(x), info)\n",
    "print affiliation\n",
    "affiliation = map(lambda x: str(x).split('>')[1].split('<')[0].decode('utf8'), affiliation)\n",
    "print affiliation\n",
    "print('Affiliation:',affiliation)\n",
    "\n",
    "\n",
    "# citations\n",
    "info = soup.findAll('div', { \"class\" : \"citedByEntry\" })\n",
    "ncitations = len(info)\n",
    "print('Ncitations:',ncitations)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's now select a volume and get info for all papers in different issues and store them in .csv tables and pickles to be used later on in our statistical analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected volumes [u'https://library.seg.org/toc/gpysa7/82/6', u'https://library.seg.org/toc/gpysa7/82/5', u'https://library.seg.org/toc/gpysa7/82/4', u'https://library.seg.org/toc/gpysa7/82/3', u'https://library.seg.org/toc/gpysa7/82/2', u'https://library.seg.org/toc/gpysa7/82/1']\n",
      "Volume https://library.seg.org/toc/gpysa7/82/6\n",
      "Editor's corner: 2\n",
      "Geophysics Letters: 1\n",
      "Case Histories: 6\n",
      "Anisotropy: 4\n",
      "Borehole Geophysics: 4\n",
      "Electrical and Electromagnetic Methods: 6\n",
      "Engineering and Environmental Geophysics: 1\n",
      "Gravity Exploration Methods: 2\n",
      "Ground-penetrating Radar: 1\n",
      "Interdisciplinary Studies: 2\n",
      "Magnetic Exploration Methods: 1\n",
      "Magnetic Resonance Sounding: 2\n",
      "Passive Seismic Methods: 2\n",
      "Reservoir Geophysics: 1\n",
      "Rock Physics: 5\n",
      "Seismic Amplitude Interpretation: 1\n",
      "Seismic Attributes and Pattern Recognition: 2\n",
      "Seismic Data Acquisition: 4\n",
      "Seismic Interferometry : 2\n",
      "Seismic Inversion: 2\n",
      "Seismic Migration: 7\n",
      "Seismic Modeling and Wave Propagation: 1\n",
      "Seismic Velocity/Statics: 2\n",
      "Signal Processing: 3\n",
      "Reproducible research: Geophysics papers of the future: 7\n",
      "Sleep for 2\n",
      "DOI http://library.seg.org/doi/abs/10.1190/geo2017-1005-tiogeo.1\n",
      "Title: This issue of Geophysics\n",
      "Category: Editor's corner\n",
      "Authors: []\n",
      "Keywords: -\n",
      "Countries: []\n",
      "Affiliations: []\n",
      "Publication history: (datetime.datetime(2017, 10, 25, 0, 0), datetime.datetime(2017, 10, 25, 0, 0), datetime.datetime(2017, 10, 25, 0, 0))\n",
      "\n",
      "Number of citations: 0\n",
      "\n",
      "Sleep for 3\n",
      "DOI http://library.seg.org/doi/abs/10.1190/geo2017-1006-tiogeo.1\n",
      "Title: Some guidelines for submitting software to “Software and Algorithms”\n",
      "Category: Editor's corner\n",
      "Authors: [u'Joe Dellinger']\n",
      "Keywords: -\n",
      "Countries: []\n",
      "Affiliations: []\n",
      "Publication history: (datetime.datetime(2017, 10, 26, 0, 0), datetime.datetime(2017, 10, 26, 0, 0), datetime.datetime(2017, 10, 26, 0, 0))\n",
      "\n",
      "Number of citations: 0\n",
      "\n",
      "Sleep for 0\n",
      "DOI http://library.seg.org/doi/abs/10.1190/geo2017-0237.1\n",
      "Title: A self-potential investigation of submarine massive sulfides: Palinuro Seamount, Tyrrhenian Sea\n",
      "Category: Geophysics Letters\n",
      "Authors: [u'Roxana Safipour', u'Sebastian H\\xf6lz', u'Jesse Halbach', u'Marion Jegen', u'Sven Petersen', u'Andrei Swidinsky']\n",
      "Keywords: ['marine', ' seafloor', ' mining', ' electrical/resistivity']\n",
      "Countries: [u'USA', u'Germany']\n",
      "Affiliations: [u'Colorado School of Mines', u'GEOMAR, Helmholtz Centre for Ocean Research']\n",
      "Publication history: (datetime.datetime(2017, 4, 19, 0, 0), datetime.datetime(2017, 8, 11, 0, 0), datetime.datetime(2017, 10, 6, 0, 0))\n",
      "\n",
      "Number of citations: 0\n",
      "\n",
      "Sleep for 9\n",
      "DOI http://library.seg.org/doi/abs/10.1190/geo2017-0071.1\n",
      "Title: Case history: A 5 km long waterborne geophysical survey along the Po river within the city of Turin (northwest Italy)\n",
      "Category: Case Histories\n",
      "Authors: [u'Luigi Sambuelli', u'Adriano Fiorucci', u'Paolo Dabove', u'Ivan Pascal', u'Chiara Colombero', u'Cesare Comina']\n",
      "Keywords: ['waterborne geophysical surveys', ' riverbed deposits', ' underwater geologic environment']\n",
      "Countries: [u'Italy']\n",
      "Affiliations: [u'Department of Environment', u'Universit\\xe0 degli Studi di Torino']\n",
      "Publication history: (datetime.datetime(2017, 1, 31, 0, 0), datetime.datetime(2017, 6, 29, 0, 0), datetime.datetime(2017, 8, 21, 0, 0))\n",
      "\n",
      "Number of citations: 0\n",
      "\n",
      "Sleep for 4\n",
      "DOI http://library.seg.org/doi/abs/10.1190/geo2017-0070.1\n",
      "Title: A comparison of loop time-domain electromagnetic and short-offset transient electromagnetic methods for mapping water-enriched zones — A case history in Shaanxi, China\n",
      "Category: Case Histories\n",
      "Authors: [u'Weiying Chen', u'Guoqiang Xue', u'Afolagboye Lekan Olatayo', u'Kang Chen', u'Muhammad Younis Khan', u'Weichang Chen', u'Linbo Zhang', u'Wen Chen']\n",
      "Keywords: ['electromagnetics', ' case history']\n",
      "Countries: [u'China', u'China', u'China', u'Pakistan']\n",
      "Affiliations: [u'Institute of Geology and Geophysics', u'Institute of Geology and Geophysics', u'Institute of Geology and Geophysics', u'University of Peshawar']\n",
      "Publication history: (datetime.datetime(2017, 1, 31, 0, 0), datetime.datetime(2017, 7, 3, 0, 0), datetime.datetime(2017, 8, 29, 0, 0))\n",
      "\n",
      "Number of citations: 0\n",
      "\n",
      "Sleep for 7\n",
      "DOI http://library.seg.org/doi/abs/10.1190/geo2017-0136.1\n",
      "Title: Vertical seismic profiling using double-beamforming processing of nonuniform anthropogenic seismic noise: The case study of Rittershoffen, Upper Rhine Graben, France\n",
      "Category: Case Histories\n",
      "Authors: [u'Maximilien Lehujeur', u'J\\xe9r\\xf4me Vergne', u'Alessia Maggi', u'Jean Schmittbuhl']\n",
      "Keywords: ['noise', ' correlation', ' geothermal', ' profiling', ' inversion']\n",
      "Countries: [u'France']\n",
      "Affiliations: [u'Universit\\xe9 de Strasbourg/EOST']\n",
      "Publication history: (datetime.datetime(2017, 3, 1, 0, 0), datetime.datetime(2017, 7, 27, 0, 0), datetime.datetime(2017, 9, 25, 0, 0))\n",
      "\n",
      "Number of citations: 0\n",
      "\n",
      "Sleep for 2\n",
      "DOI http://library.seg.org/doi/abs/10.1190/geo2017-0041.1\n",
      "Title: Integrated facies modeling in unconventional reservoirs using a frequentist approach: Example from a South Texas field\n",
      "Category: Case Histories\n",
      "Authors: [u'Reinaldo J. Michelena', u'Kevin S. Godbey', u'Omar G. Angola']\n",
      "Keywords: ['unconventional', ' lithology', ' horizontal wells', ' integration', ' statistics']\n",
      "Countries: [u'USA']\n",
      "Affiliations: [u'iReservoir.com Inc.']\n",
      "Publication history: (datetime.datetime(2017, 1, 18, 0, 0), datetime.datetime(2017, 6, 29, 0, 0), datetime.datetime(2017, 9, 25, 0, 0))\n",
      "\n",
      "Number of citations: 0\n",
      "\n",
      "Sleep for 4\n",
      "DOI http://library.seg.org/doi/abs/10.1190/geo2017-0016.1\n",
      "Title: Assessment of soil-liquefaction potential based on geoelectrical imaging: A case study\n",
      "Category: Case Histories\n",
      "Authors: [u'Rajni Devi', u'Rambhatla G. Sastry', u'Narendra K. Samadhiya']\n",
      "Keywords: ['engineering', ' environmental', ' earthquake', ' electrical/resistivity']\n",
      "Countries: [u'India', u'India']\n",
      "Affiliations: [u'Indian Institute of Technology Roorkee', u'Indian Institute of Technology Roorkee']\n",
      "Publication history: (datetime.datetime(2017, 1, 7, 0, 0), datetime.datetime(2017, 8, 6, 0, 0), datetime.datetime(2017, 10, 23, 0, 0))\n",
      "\n",
      "Number of citations: 0\n",
      "\n",
      "Sleep for 3\n",
      "DOI http://library.seg.org/doi/abs/10.1190/geo2016-0440.1\n",
      "Title: Determining geophysical responses from burials in graveyards and cemeteries\n",
      "Category: Case Histories\n",
      "Authors: [u'Henry C. Dick', u'Jamie K. Pringle', u'Kristopher D. Wisniewski', u'Jon Goodwin', u'Robert van der Putten', u'Gethin T. Evans', u'James D. Francis', u'John P. Cassella', u'Jamie D. Hansen']\n",
      "Keywords: ['case history', ' GPR', ' electrical/resistivity', ' magnetic susceptibility']\n",
      "Countries: [u'UK', u'UK', u'UK']\n",
      "Affiliations: [u'Keele University', u'Stoke-on-Trent Archaeology Service', u'Staffordshire University']\n",
      "Publication history: (datetime.datetime(2016, 8, 16, 0, 0), datetime.datetime(2017, 7, 26, 0, 0), datetime.datetime(2017, 10, 27, 0, 0))\n",
      "\n",
      "Number of citations: 0\n",
      "\n",
      "Sleep for 2\n",
      "DOI http://library.seg.org/doi/abs/10.1190/geo2016-0486.1\n",
      "Title: Traveltime parameters in tilted orthorhombic medium\n",
      "Category: Anisotropy\n",
      "Authors: [u'Yuriy Ivanov', u'Alexey Stovas']\n",
      "Keywords: ['3D', ' anisotropy', ' layered', ' moveout', ' neural networks']\n",
      "Countries: [u'Norway']\n",
      "Affiliations: [u'Norwegian University of Science and Technology']\n",
      "Publication history: (datetime.datetime(2016, 9, 14, 0, 0), datetime.datetime(2017, 6, 29, 0, 0), datetime.datetime(2017, 9, 6, 0, 0))\n",
      "\n",
      "Number of citations: 0\n",
      "\n",
      "Sleep for 3\n",
      "DOI http://library.seg.org/doi/abs/10.1190/geo2016-0459.1\n",
      "Title: Elastic properties of two VTI shale samples as a function of uniaxial stress: Experimental results and application of the porosity-deformation approach\n",
      "Category: Anisotropy\n",
      "Authors: [u'Viacheslav A. Sviridov', u'Sibylle I. Mayr', u'Serge A. Shapiro']\n",
      "Keywords: ['anisotropy', ' elastic', ' ultrasonic', ' shale gas', ' rock physics']\n",
      "Countries: [u'Germany']\n",
      "Affiliations: [u'Freie Universit\\xe4t Berlin']\n",
      "Publication history: (datetime.datetime(2016, 8, 30, 0, 0), datetime.datetime(2017, 7, 3, 0, 0), datetime.datetime(2017, 9, 25, 0, 0))\n",
      "\n",
      "Number of citations: 0\n",
      "\n",
      "Sleep for 1\n",
      "DOI http://library.seg.org/doi/abs/10.1190/geo2017-0191.1\n",
      "Title: Azimuthally anisotropic elastic impedance inversion for fluid indicator driven by rock physics\n",
      "Category: Anisotropy\n",
      "Authors: [u'Xinpeng Pan', u'Guangzhi Zhang', u'Xingyao Yin']\n",
      "Keywords: ['fracture fluid indicator', ' azimuthally anisotropic elastic impedance inversion', ' anisotropic rock-physics model', ' fracture weaknesses', ' fluid identification']\n",
      "Countries: [u'China', u'China']\n",
      "Affiliations: [u'China University of Petroleum', u'Qingdao National Laboratory for Marine Science and Technology']\n",
      "Publication history: (datetime.datetime(2017, 3, 25, 0, 0), datetime.datetime(2017, 8, 12, 0, 0), datetime.datetime(2017, 10, 5, 0, 0))\n",
      "\n",
      "Number of citations: 0\n",
      "\n",
      "Sleep for 2\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOI http://library.seg.org/doi/abs/10.1190/geo2017-0215.1\n",
      "Title: A new parameterization for acoustic orthorhombic media\n",
      "Category: Anisotropy\n",
      "Authors: [u'Shibo Xu', u'Alexey Stovas']\n",
      "Keywords: ['traveltime approximation', ' orthorhombic model', ' seismic modeling']\n",
      "Countries: [u'Norway']\n",
      "Affiliations: [u'Norwegian University of Science and Technology']\n",
      "Publication history: (datetime.datetime(2017, 4, 10, 0, 0), datetime.datetime(2017, 8, 11, 0, 0), datetime.datetime(2017, 10, 5, 0, 0))\n",
      "\n",
      "Number of citations: 0\n",
      "\n",
      "Sleep for 5\n",
      "DOI http://library.seg.org/doi/abs/10.1190/geo2016-0545.1\n",
      "Title: Application of nanoindentation for uncertainty assessment of elastic properties in mudrocks from micro- to well-log scales\n",
      "Category: Borehole Geophysics\n",
      "Authors: [u'Clotilde Chen Valdes', u'Zoya Heidari']\n",
      "Keywords: ['elastic', ' acoustic', ' log analysis']\n",
      "Countries: [u'USA', u'USA']\n",
      "Affiliations: [u'Texas A&amp;M University', u'The University of Texas at Austin']\n",
      "Publication history: (datetime.datetime(2016, 10, 24, 0, 0), datetime.datetime(2017, 6, 26, 0, 0), datetime.datetime(2017, 9, 6, 0, 0))\n",
      "\n",
      "Number of citations: 0\n",
      "\n",
      "Sleep for 4\n",
      "DOI http://library.seg.org/doi/abs/10.1190/geo2016-0592.1\n",
      "Title: Weighted processing for microresistivity imaging logging in oil-based mud using a support vector regression model\n",
      "Category: Borehole Geophysics\n",
      "Authors: [u'Jian-Shen Gao', u'Jian-Meng Sun', u'Yan-Jiao Jiang', u'Peng-Yun Zhang', u'Jie Wu']\n",
      "Keywords: ['apparent resistivity', ' logging', ' imaging', ' optimization']\n",
      "Countries: [u'China', u'China', u'China']\n",
      "Affiliations: [u'Xi\\u2019an Shiyou University', u'China University of Petroleum (East)', u'Northeast Petroleum University']\n",
      "Publication history: (datetime.datetime(2016, 11, 17, 0, 0), datetime.datetime(2017, 7, 3, 0, 0), datetime.datetime(2017, 9, 6, 0, 0))\n",
      "\n",
      "Number of citations: 0\n",
      "\n",
      "Sleep for 1\n",
      "DOI http://library.seg.org/doi/abs/10.1190/geo2017-0201.1\n",
      "Title: Characteristics of waveforms recorded by azimuthally spaced hydrophones of sonic logging tool for incident plane waves\n",
      "Category: Borehole Geophysics\n",
      "Authors: [u'Nobuyasu Hirabayashi', u'Naoki Sakiyama', u'Toru Ikegami']\n",
      "Keywords: ['borehole geophysics', ' modeling', ' sonic', ' hydrophones']\n",
      "Countries: [u'Japan']\n",
      "Affiliations: [u'Schlumberger']\n",
      "Publication history: (datetime.datetime(2017, 4, 3, 0, 0), datetime.datetime(2017, 7, 16, 0, 0), datetime.datetime(2017, 9, 25, 0, 0))\n",
      "\n",
      "Number of citations: 0\n",
      "\n",
      "Sleep for 7\n",
      "DOI http://library.seg.org/doi/abs/10.1190/geo2017-0080.1\n",
      "Title: Local and global fluid effects on sonic wave modes\n",
      "Category: Borehole Geophysics\n",
      "Authors: [u'Elliot J. H. Dahl', u'Kyle T. Spikes']\n",
      "Keywords: ['acoustic', ' borehole geophysics', ' dispersion', ' rock physics', ' wave propagation']\n",
      "Countries: [u'USA']\n",
      "Affiliations: [u'The University of Texas at Austin']\n",
      "Publication history: (datetime.datetime(2017, 2, 1, 0, 0), datetime.datetime(2017, 8, 11, 0, 0), datetime.datetime(2017, 10, 6, 0, 0))\n",
      "\n",
      "Number of citations: 0\n",
      "\n",
      "Sleep for 4\n",
      "DOI http://library.seg.org/doi/abs/10.1190/geo2016-0700.1\n",
      "Title: On electric fields produced by inductive sources on the seafloor\n",
      "Category: Electrical and Electromagnetic Methods\n",
      "Authors: [u'Roxana Safipour', u'Sebastian H\\xf6lz', u'Marion Jegen', u'Andrei Swidinsky']\n",
      "Keywords: ['marine', ' electromagnetics', ' mining', ' modeling']\n",
      "Countries: [u'USA', u'Germany']\n",
      "Affiliations: [u'Colorado School of Mines', u'GEOMAR']\n",
      "Publication history: (datetime.datetime(2016, 12, 27, 0, 0), datetime.datetime(2017, 6, 29, 0, 0), datetime.datetime(2017, 8, 21, 0, 0))\n",
      "\n",
      "Number of citations: 0\n",
      "\n",
      "Sleep for 6\n",
      "DOI http://library.seg.org/doi/abs/10.1190/geo2016-0277.1\n",
      "Title: Splitting marine controlled-source electromagnetic responses into sea and subseafloor contributions: Grounding the air wave\n",
      "Category: Electrical and Electromagnetic Methods\n",
      "Authors: [u'Armando Calder\\xf3n-Moctezuma', u'Enrique G\\xf3mez-Trevi\\xf1o', u'Luis A. Gallardo']\n",
      "Keywords: ['electromagnetic', ' marine CSEM', ' land CSEM', ' air wave', ' sensitivity']\n",
      "Countries: [u'M\\xe9xico']\n",
      "Affiliations: [u'CICESE']\n",
      "Publication history: (datetime.datetime(2016, 5, 26, 0, 0), datetime.datetime(2017, 6, 20, 0, 0), datetime.datetime(2017, 8, 21, 0, 0))\n",
      "\n",
      "Number of citations: 0\n",
      "\n",
      "Sleep for 3\n",
      "DOI http://library.seg.org/doi/abs/10.1190/geo2017-0024.1\n",
      "Title: A new approach for time-lapse data weighting in electrical resistivity tomography\n",
      "Category: Electrical and Electromagnetic Methods\n",
      "Authors: [u'Nolwenn Lesparre', u'Frederic Nguyen', u'Andreas Kemna', u'Tanguy Robert', u'Thomas Hermans', u'Moubarak Daoudi', u'Adrian Flores-Orozco']\n",
      "Keywords: ['electrical/resistivity', ' imaging', ' inversion', ' noise', ' time lapse']\n",
      "Countries: [u'Belgium', u'Germany', u'Belgium', u'Belgium', u'Belgium', u'Belgium', u'Belgium', u'Austria']\n",
      "Affiliations: [u'University of Li\\xe8ge', u'University of Bonn', u'University of Li\\xe8ge', u'R&amp;D Department', u'University of Li\\xe8ge', u'FNRS', u'ABESIM', u'TU Wien']\n",
      "Publication history: (datetime.datetime(2017, 1, 11, 0, 0), datetime.datetime(2017, 7, 3, 0, 0), datetime.datetime(2017, 8, 26, 0, 0))\n",
      "\n",
      "Number of citations: 0\n",
      "\n",
      "Sleep for 8\n",
      "DOI http://library.seg.org/doi/abs/10.1190/geo2015-0394.1\n",
      "Title: 3D marine magnetotelluric inversion: A hybrid impedance and direct-field approach\n",
      "Category: Electrical and Electromagnetic Methods\n",
      "Authors: [u'Lutz M\\xfctschard', u'Ketil Hokstad', u'Torgeir Wiik', u'Bj\\xf8rn Ursin']\n",
      "Keywords: ['3D', ' inversion', ' magnetotelluric']\n",
      "Countries: [u'Norway', u'Norway', u'Norway', u'Norway']\n",
      "Affiliations: [u'NTNU Norwegian University of Science and Engineering', u'Statoil Research Centre Rotvoll', u'NTNU Norwegian University of Science and Engineering', u'Statoil Research Centre Rotvoll']\n",
      "Publication history: (datetime.datetime(2015, 7, 22, 0, 0), datetime.datetime(2017, 6, 20, 0, 0), datetime.datetime(2017, 10, 6, 0, 0))\n",
      "\n",
      "Number of citations: 0\n",
      "\n",
      "Sleep for 4\n",
      "DOI http://library.seg.org/doi/abs/10.1190/geo2017-0223.1\n",
      "Title: Superparamagnetism in ground and airborne electromagnetics: Geometrical and physical controls\n",
      "Category: Electrical and Electromagnetic Methods\n",
      "Authors: [u'James Macnae']\n",
      "Keywords: ['superparamagnetism', ' electromagnetics', ' maghemite', ' nanoparticle', ' demagnetization']\n",
      "Countries: [u'Australia']\n",
      "Affiliations: [u'RMIT University']\n",
      "Publication history: (datetime.datetime(2017, 4, 12, 0, 0), datetime.datetime(2017, 8, 11, 0, 0), datetime.datetime(2017, 10, 6, 0, 0))\n",
      "\n",
      "Number of citations: 0\n",
      "\n",
      "Sleep for 7\n",
      "DOI http://library.seg.org/doi/abs/10.1190/geo2016-0518.1\n",
      "Title: Fast 3D multichannel deconvolution of electromagnetic induction loop-loop apparent conductivity data sets acquired at low induction numbers\n",
      "Category: Electrical and Electromagnetic Methods\n",
      "Authors: [u'Julien Guillemoteau', u'Niels B\\xf8ie Christensen', u'Bo Holm Jacobsen', u'Jens Tronicke']\n",
      "Keywords: ['electromagnetics', ' 3D', ' inversion', ' environmental', ' near surface']\n",
      "Countries: [u'Germany', u'Denmark']\n",
      "Affiliations: [u'University of Potsdam', u'University of Aarhus']\n",
      "Publication history: (datetime.datetime(2016, 10, 6, 0, 0), datetime.datetime(2017, 8, 12, 0, 0), datetime.datetime(2017, 10, 19, 0, 0))\n",
      "\n",
      "Number of citations: 0\n",
      "\n",
      "Sleep for 6\n",
      "DOI http://library.seg.org/doi/abs/10.1190/geo2016-0654.1\n",
      "Title: A comprehensive comparison between the refraction microtremor and seismic interferometry methods for phase-velocity estimation\n",
      "Category: Engineering and Environmental Geophysics\n",
      "Authors: [u'Zongbo Xu', u'T. Dylan Mikesell', u'Jianghai Xia', u'Feng Cheng']\n",
      "Keywords: ['interferometry', ' surface wave', ' passive seismic', ' dispersion', ' Radon transform']\n",
      "Countries: [u'USA', u'China', u'China']\n",
      "Affiliations: [u'Boise State University', u'Zhejiang University', u'The China University of Geosciences']\n",
      "Publication history: (datetime.datetime(2016, 12, 6, 0, 0), datetime.datetime(2017, 7, 25, 0, 0), datetime.datetime(2017, 10, 3, 0, 0))\n",
      "\n",
      "Number of citations: 0\n",
      "\n",
      "Sleep for 0\n",
      "DOI http://library.seg.org/doi/abs/10.1190/geo2016-0451.1\n",
      "Title: Adaptive multinary inversion of gravity and gravity gradiometry data\n",
      "Category: Gravity Exploration Methods\n",
      "Authors: [u'Michael S. Zhdanov', u'Wei Lin']\n",
      "Keywords: ['3D', ' gravity', ' inversion']\n",
      "Countries: [u'USA', u'USA', u'Russia', u'USA']\n",
      "Affiliations: [u'University of Utah', u'TechnoImaging', u'Moscow Institute of Physics and Technology', u'University of Utah']\n",
      "Publication history: (datetime.datetime(2016, 8, 24, 0, 0), datetime.datetime(2017, 7, 7, 0, 0), datetime.datetime(2017, 8, 29, 0, 0))\n",
      "\n",
      "Number of citations: 0\n",
      "\n",
      "Sleep for 8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DOI http://library.seg.org/doi/abs/10.1190/geo2016-0418.1\n",
      "Title: Mathematical properties and physical meaning of the gravity gradient tensor eigenvalues\n",
      "Category: Gravity Exploration Methods\n",
      "Authors: [u'Carlos Cevallos']\n",
      "Keywords: ['gravity', ' gradient', ' tensor', ' eigenvalues']\n",
      "Countries: [u'Australia']\n",
      "Affiliations: [u'Consultant']\n",
      "Publication history: (datetime.datetime(2016, 8, 4, 0, 0), datetime.datetime(2017, 6, 29, 0, 0), datetime.datetime(2017, 9, 6, 0, 0))\n",
      "\n",
      "Number of citations: 0\n",
      "\n",
      "Sleep for 2\n",
      "DOI http://library.seg.org/doi/abs/10.1190/geo2016-0008.1\n",
      "Title: Joint acoustic full-waveform inversion of crosshole seismic and ground-penetrating radar data in the frequency domain\n",
      "Category: Ground-penetrating Radar\n",
      "Authors: [u'Xuan Feng', u'Qianci Ren', u'Cai Liu', u'Xuebing Zhang']\n",
      "Keywords: ['joint inversion', ' cross-gradient constraint', ' full-waveform inversion', ' crosshole seismic', ' crosshole GPR', ' truncated Newton method']\n",
      "Countries: [u'USA', u'China', u'China']\n",
      "Affiliations: [u'Massachusetts Institute of Technology', u'Jilin University', u'Jilin University']\n",
      "Publication history: (datetime.datetime(2016, 1, 4, 0, 0), datetime.datetime(2017, 7, 27, 0, 0), datetime.datetime(2017, 9, 25, 0, 0))\n",
      "\n",
      "Number of citations: 0\n",
      "\n",
      "Sleep for 5\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-a8c12338ee47>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     51\u001b[0m                 np.random.uniform(0,10))\n\u001b[1;32m     52\u001b[0m             \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Sleep for %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mtime_sleep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m             \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msleep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime_sleep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m             \u001b[0;31m# Make the request\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "scrapedvolumes = ['82']  # list of volumes to scrape\n",
    "ndois          = -1      # number of dois to process, if -1 all dois\n",
    "\n",
    "\n",
    "for scrapedvolume in scrapedvolumes:\n",
    "\n",
    "    selvolumes = filter(lambda x: scrapedvolume in str(x), [volume[0] for volume in volumes])\n",
    "    print ('Selected volumes %s' % selvolumes)\n",
    "\n",
    "    for ivolume,volume in enumerate(selvolumes):\n",
    "\n",
    "        print('Volume %s' % volume)\n",
    "\n",
    "        # Create folder to save useful info\n",
    "        vol, issue = volume.split('/')[-2:]\n",
    "\n",
    "        folder='/'.join(volume.split('/')[-2:]) \n",
    "        if not os.path.exists(folder):\n",
    "            os.makedirs(folder)\n",
    "\n",
    "        # Initialize containers\n",
    "        df_seg    = pd.DataFrame()\n",
    "        titles    = []\n",
    "        authors   = []\n",
    "        countries = []\n",
    "        affiliations = []\n",
    "        keywords  = []\n",
    "        abstracts = []\n",
    "\n",
    "        # make request\n",
    "        r = requests.get(volume)\n",
    "        html = r.text\n",
    "        #print html\n",
    "\n",
    "        # find categories for each doi\n",
    "        categories = find_categories(html)\n",
    "\n",
    "        # find all dois\n",
    "        dois = re.findall('\"((https)s?://doi.*?)\"', html)\n",
    "        #print dois\n",
    "\n",
    "        # remove first doi as it is ' This issue of Geophysics '\n",
    "        #dois = dois[1:]\n",
    "        dois = dois[:len(categories)]\n",
    "\n",
    "        # loop over dois and extract info\n",
    "        for idoi, doi in enumerate(dois[:ndois]):\n",
    "\n",
    "            # sleep for some time to avoid being found web scraping ;)\n",
    "            time_sleep=np.round(\n",
    "                np.random.uniform(0,10))\n",
    "            print('Sleep for %d' % time_sleep)\n",
    "            time.sleep(time_sleep)\n",
    "            \n",
    "            # Make the request \n",
    "            #print('DOI %s' % doi[0])\n",
    "            #r = requests.get(doi[0])\n",
    "            \n",
    "            # rearrange doi to work with volumes before 79\n",
    "            doi = '/'.join(['http://library.seg.org/doi/abs','/'.join(doi[0].split('/')[-2:])])\n",
    "\n",
    "            print('DOI %s' % doi)\n",
    "            r = requests.get(doi)\n",
    "\n",
    "            # Extract HTML from Response object\n",
    "            html = r.text\n",
    "            #print html\n",
    "\n",
    "            # Create a BeautifulSoup object from the HTML\n",
    "            soup = BeautifulSoup(html, \"html5lib\")\n",
    "\n",
    "\n",
    "            # GET USEFUL INFO #\n",
    "            info    = soup.findAll('meta')\n",
    "            infopub = soup.findAll(text=re.compile(\"Received:|Accepted:|Published:\"))\n",
    "            infoaff = soup.findAll('span')\n",
    "\n",
    "\n",
    "            # Get title\n",
    "            title = soup.title.string.split('GEOPHYSICS')[0][18:-3]\n",
    "            print('Title: %s' % title)\n",
    "            titles.append(title)\n",
    "\n",
    "            # Get category\n",
    "            category = categories[idoi]\n",
    "            print('Category: %s' % category)\n",
    "\n",
    "\n",
    "            # Get authors\n",
    "            author    = filter(lambda x: 'dc.Creator' in str(x), info)\n",
    "            author_df = map(lambda x: str(x).split('\"')[1], author)\n",
    "            author    = map(lambda x: str(x).split('\"')[1].decode('utf8'), author)\n",
    "\n",
    "            print('Authors: %s' % author)\n",
    "            authors.extend(author)\n",
    "\n",
    "\n",
    "            # Get keywords\n",
    "            keyword     = filter(lambda x: 'dc.Subject' in str(x), info)\n",
    "            if len(keyword)>0:\n",
    "                keyword_df  = map(lambda x: str(x).split('\"')[1], keyword)#.decode('utf8')\n",
    "                keyword     = map(lambda x: str(x).split('\"')[1], keyword)\n",
    "                keyword     = map(lambda x: str(x).split(';'), keyword)[0]\n",
    "            else:\n",
    "                keyword_df='-'\n",
    "                keyword='-'\n",
    "            print('Keywords: %s' % keyword)\n",
    "            keywords.extend(keyword)\n",
    "\n",
    "\n",
    "            # Get abstracts\n",
    "            abstract = filter(lambda x: 'dc.Description' in str(x), info)\n",
    "            if len(abstract)>0:\n",
    "                abstract = map(lambda x: str(x).split('\"')[1].decode('utf8'), abstract)[0][8:]\n",
    "            else:\n",
    "                abstract='-'\n",
    "            #print('Abstract: %s' % abstract)\n",
    "            abstracts.extend(abstract)\n",
    "\n",
    "\n",
    "            # Get countries\n",
    "            country    = filter(lambda x: 'country' in str(x), infoaff)\n",
    "            country_df = map(lambda x: str(x).split('>')[1].split('<')[0], country)\n",
    "            country    = map(lambda x: str(x).split('>')[1].split('<')[0].decode('utf8'), country)\n",
    "\n",
    "            print('Countries: %s' % country)\n",
    "            countries.extend(country)\n",
    "\n",
    "\n",
    "            # Get affiliations\n",
    "            affiliation    = filter(lambda x: 'institution' in str(x), infoaff)\n",
    "            affiliation_df = map(lambda x: str(x).split('>')[1].split('<')[0], affiliation)\n",
    "            affiliation    = map(lambda x: str(x).split('>')[1].split('<')[0].decode('utf8'), affiliation)\n",
    "\n",
    "            print('Affiliations: %s' % affiliation)\n",
    "            affiliations.extend(affiliation)\n",
    "\n",
    "\n",
    "            # Get publication history\n",
    "            pubhistory = get_pubhistory(infopub)\n",
    "            print('Publication history: %s\\n' % str(pubhistory))\n",
    "\n",
    "\n",
    "            # Get number of citations\n",
    "            citations = soup.findAll('div', { \"class\" : \"citedByEntry\" })\n",
    "            ncitations = len(citations)\n",
    "            print('Number of citations: %d\\n' % ncitations)\n",
    "\n",
    "\n",
    "            # check that I am not being banned by website...\n",
    "            #if len(author)==0:\n",
    "            #    print('Last DOI %s')\n",
    "            #    raise Exception('No Authors')\n",
    "\n",
    "            df_seg = df_seg.append(pd.DataFrame({'Title'         : title.encode('utf8'), \n",
    "                                                 'Category'      : category.encode('utf8'),\n",
    "                                                 'Authors'       : ('; ').join(author_df),\n",
    "                                                 'Countries'     : ('; ').join(country_df),\n",
    "                                                 'Affiliations'  : ('; ').join(affiliation_df),\n",
    "                                                 'Keywords'      : keyword_df[0],\n",
    "                                                 'Received'      : pd.Timestamp(pubhistory[0]),\n",
    "                                                 'Accepted'      : pd.Timestamp(pubhistory[1]),\n",
    "                                                 'Published'     : pd.Timestamp(pubhistory[2]),\n",
    "                                                 'Volume'        : vol,\n",
    "                                                 'Issue'         : issue,\n",
    "                                                 'Ncitations'    : ncitations}, index=[0]), ignore_index=True)\n",
    "\n",
    "\n",
    "        # save dataframe\n",
    "        df_seg.to_csv(pathSEG+folder+'/df_SEG.csv')\n",
    "\n",
    "        # loop through titles and get all words\n",
    "        words_title = words_from_text(titles)\n",
    "        #print words_title\n",
    "        #words_title = [x.encode('utf-8') for x in words_title]\n",
    "\n",
    "        # loop through abstracts and get all words\n",
    "        words_abstract = words_from_text(abstracts)\n",
    "        #print words_abstract\n",
    "\n",
    "        # Save words and authors into pickles\n",
    "        with open(pathSEG+folder+'/wordstitle_SEG', 'wb') as fp:\n",
    "            pickle.dump(words_title, fp)\n",
    "\n",
    "        with open(pathSEG+folder+'/wordsabstract_SEG', 'wb') as fp:\n",
    "            pickle.dump(words_abstract, fp)\n",
    "\n",
    "        with open(pathSEG+folder+'/authors_SEG', 'wb') as fp:\n",
    "            pickle.dump(authors, fp)\n",
    "\n",
    "        with open(pathSEG+folder+'/countries_SEG', 'wb') as fp:\n",
    "            pickle.dump(countries, fp)\n",
    "\n",
    "        with open(pathSEG+folder+'/affiliations_SEG', 'wb') as fp:\n",
    "            pickle.dump(affiliations, fp)\n",
    "   \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
